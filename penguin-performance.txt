Base Decision Tree for Penguins
---------------------------------
(A) Best Hyperparameters for Penguin: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}
Best Hyperparameters for Top-MLP Penguin:{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'sgd'}
---------------------------------
(B) Confusion Matrix:
Base-DT 
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Top-DT 
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Base-MLP 
[[29  0  2]
 [13  0  0]
 [ 1  0 22]]
Top-MLP 
[[31  0  0]
 [13  0  0]
 [23  0  0]]
---------------------------------
(C) Classification Report:
Base-DT
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

Top-DT
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

Base-MLP
              precision    recall  f1-score   support

      Adelie       0.67      0.94      0.78        31
   Chinstrap       0.00      0.00      0.00        13
      Gentoo       0.92      0.96      0.94        23

    accuracy                           0.76        67
   macro avg       0.53      0.63      0.57        67
weighted avg       0.63      0.76      0.68        67

Top-MLP
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        31
   Chinstrap       0.00      0.00      0.00        13
      Gentoo       0.00      0.00      0.00        23

    accuracy                           0.46        67
   macro avg       0.15      0.33      0.21        67
weighted avg       0.21      0.46      0.29        67

---------------------------------
(D) Accuracy, Macro-average F1, and Weighted-average F1:
Accuracy for Base-DT: 1.0000


Accuracy for Top-DT: 1.0000


Accuracy for Base-MLP: 0.7612


Accuracy for Top-MLP: 0.4627


Macro-average F1 for Top-DT: 1.0000


Macro-average F1 for Base-DT: 1.0000


Macro-average F1 for Base-MLP: 0.5733


Macro-average F1 for Top-MLP: 0.2109


Weighted-average F1 for Base-DT: 1.0000


Weighted-average F1 for Top-DT: 1.0000


Weighted-average F1 for Base-MLP: 0.6840


Weighted-average F1 for Top-MLP: 0.2927


Base Decision Tree for Penguins
---------------------------------
(A) Best Hyperparameters for Penguin: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}
Best Hyperparameters for Top-MLP Penguin:{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'sgd'}
---------------------------------
(B) Confusion Matrix:
Base-DT 
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Top-DT 
[[30  1  0]
 [ 0 13  0]
 [ 0  0 23]]
Base-MLP 
[[29  0  2]
 [13  0  0]
 [ 1  0 22]]
Top-MLP 
[[31  0  0]
 [13  0  0]
 [23  0  0]]
---------------------------------
(C) Classification Report:
Base-DT
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

Top-DT
              precision    recall  f1-score   support

      Adelie       1.00      0.97      0.98        31
   Chinstrap       0.93      1.00      0.96        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           0.99        67
   macro avg       0.98      0.99      0.98        67
weighted avg       0.99      0.99      0.99        67

Base-MLP
              precision    recall  f1-score   support

      Adelie       0.67      0.94      0.78        31
   Chinstrap       0.00      0.00      0.00        13
      Gentoo       0.92      0.96      0.94        23

    accuracy                           0.76        67
   macro avg       0.53      0.63      0.57        67
weighted avg       0.63      0.76      0.68        67

Top-MLP
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        31
   Chinstrap       0.00      0.00      0.00        13
      Gentoo       0.00      0.00      0.00        23

    accuracy                           0.46        67
   macro avg       0.15      0.33      0.21        67
weighted avg       0.21      0.46      0.29        67

---------------------------------
(D) Accuracy, Macro-average F1, and Weighted-average F1:
Accuracy for Base-DT: 1.0000


Accuracy for Top-DT: 0.9851


Accuracy for Base-MLP: 0.7612


Accuracy for Top-MLP: 0.4627


Macro-average F1 for Top-DT: 0.9822


Macro-average F1 for Base-DT: 1.0000


Macro-average F1 for Base-MLP: 0.5733


Macro-average F1 for Top-MLP: 0.2109


Weighted-average F1 for Base-DT: 1.0000


Weighted-average F1 for Top-DT: 0.9852


Weighted-average F1 for Base-MLP: 0.6840


Weighted-average F1 for Top-MLP: 0.2927


Base Decision Tree for Penguins
---------------------------------
(A) Best Hyperparameters for Penguin: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}
Best Hyperparameters for Top-MLP Penguin:{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'sgd'}
---------------------------------
(B) Confusion Matrix:
Base-DT 
[[30  1  0]
 [ 0 13  0]
 [ 0  0 23]]
Top-DT 
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Base-MLP 
[[29  0  2]
 [13  0  0]
 [ 1  0 22]]
Top-MLP 
[[31  0  0]
 [13  0  0]
 [23  0  0]]
---------------------------------
(C) Classification Report:
Base-DT
              precision    recall  f1-score   support

      Adelie       1.00      0.97      0.98        31
   Chinstrap       0.93      1.00      0.96        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           0.99        67
   macro avg       0.98      0.99      0.98        67
weighted avg       0.99      0.99      0.99        67

Top-DT
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

Base-MLP
              precision    recall  f1-score   support

      Adelie       0.67      0.94      0.78        31
   Chinstrap       0.00      0.00      0.00        13
      Gentoo       0.92      0.96      0.94        23

    accuracy                           0.76        67
   macro avg       0.53      0.63      0.57        67
weighted avg       0.63      0.76      0.68        67

Top-MLP
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        31
   Chinstrap       0.00      0.00      0.00        13
      Gentoo       0.00      0.00      0.00        23

    accuracy                           0.46        67
   macro avg       0.15      0.33      0.21        67
weighted avg       0.21      0.46      0.29        67

---------------------------------
(D) Accuracy, Macro-average F1, and Weighted-average F1:
Accuracy for Base-DT: 0.9851


Accuracy for Top-DT: 1.0000


Accuracy for Base-MLP: 0.7612


Accuracy for Top-MLP: 0.4627


Macro-average F1 for Top-DT: 1.0000


Macro-average F1 for Base-DT: 0.9822


Macro-average F1 for Base-MLP: 0.5733


Macro-average F1 for Top-MLP: 0.2109


Weighted-average F1 for Base-DT: 0.9852


Weighted-average F1 for Top-DT: 1.0000


Weighted-average F1 for Base-MLP: 0.6840


Weighted-average F1 for Top-MLP: 0.2927


(A) Average Accuracy:0.9925373134328358
(A) Variance Accuracy:5.5691690799733e-05
(B) Average Macro-F1:0.9910949200566688
(B) Variance Macro-F1:7.93004487971211e-05
(C) Average Weighted-F1 :0.9926143417702018
(C) Variance Weighted-F1 :5.454794748738585e-05
